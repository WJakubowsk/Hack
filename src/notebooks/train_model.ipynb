{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58f04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42b46300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bb995ead-f65c-43e8-9d7f-771546d21651.tiff</td>\n",
       "      <td>['parliament', 'wsrdd', 'scrambeer', 'engeyi',...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2a476c78-ce1c-4535-831c-626635b69fef.tiff</td>\n",
       "      <td>['gilvvmather', 'insertion', 'order', 'i6ken7n...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7bbd6936-4f3d-4eb4-bb75-983cbca08f48.tiff</td>\n",
       "      <td>['newport', '902', 'cosmopolitan', 'april', '1...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62d852b8-25eb-48e0-8cfe-0091c4f2453e.tiff</td>\n",
       "      <td>['goforthegołd', 'introduce', 'true', 'gqld', ...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8c5a5c2b-c58d-4f7e-985d-236bcc69011e.tiff</td>\n",
       "      <td>['what', 's', 'tobacoo', 'induisty', 'dong', '...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10824</th>\n",
       "      <td>10824</td>\n",
       "      <td>3827a69b-52cb-4600-a970-5163322ac4d7.jpg</td>\n",
       "      <td>['umowa', '0', 'dzielo', 'kukulowo', '0625', '...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>10825</td>\n",
       "      <td>671cca7a-fe43-4743-9c23-4c4a4ef5b810.jpg</td>\n",
       "      <td>['umowa', 'odiflo', 'zawrzeć', 'dzień', '20221...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10826</th>\n",
       "      <td>10826</td>\n",
       "      <td>a09e8f97-35c0-4327-9ab8-dfc2b2052722.jpg</td>\n",
       "      <td>['uowaodiflo', 'zawrzeć', 'dzień', '2020032', ...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10827</th>\n",
       "      <td>10827</td>\n",
       "      <td>42ede5e5-8b9c-48d7-8996-ca81e8408b90.jpg</td>\n",
       "      <td>['umowa', '0', 'dziłlo', 'zawrzeć', 'dzień', '...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>10828</td>\n",
       "      <td>c76876e7-1df3-4e1e-8898-cbdb7d44df72.jpg</td>\n",
       "      <td>['umowa', '0', 'dzieło', 'zawrzeć', 'dzień', '...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10829 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                       File  \\\n",
       "0               0  bb995ead-f65c-43e8-9d7f-771546d21651.tiff   \n",
       "1               1  2a476c78-ce1c-4535-831c-626635b69fef.tiff   \n",
       "2               2  7bbd6936-4f3d-4eb4-bb75-983cbca08f48.tiff   \n",
       "3               3  62d852b8-25eb-48e0-8cfe-0091c4f2453e.tiff   \n",
       "4               4  8c5a5c2b-c58d-4f7e-985d-236bcc69011e.tiff   \n",
       "...           ...                                        ...   \n",
       "10824       10824   3827a69b-52cb-4600-a970-5163322ac4d7.jpg   \n",
       "10825       10825   671cca7a-fe43-4743-9c23-4c4a4ef5b810.jpg   \n",
       "10826       10826   a09e8f97-35c0-4327-9ab8-dfc2b2052722.jpg   \n",
       "10827       10827   42ede5e5-8b9c-48d7-8996-ca81e8408b90.jpg   \n",
       "10828       10828   c76876e7-1df3-4e1e-8898-cbdb7d44df72.jpg   \n",
       "\n",
       "                                                    Text        Category  \\\n",
       "0      ['parliament', 'wsrdd', 'scrambeer', 'engeyi',...   advertisement   \n",
       "1      ['gilvvmather', 'insertion', 'order', 'i6ken7n...   advertisement   \n",
       "2      ['newport', '902', 'cosmopolitan', 'april', '1...   advertisement   \n",
       "3      ['goforthegołd', 'introduce', 'true', 'gqld', ...   advertisement   \n",
       "4      ['what', 's', 'tobacoo', 'induisty', 'dong', '...   advertisement   \n",
       "...                                                  ...             ...   \n",
       "10824  ['umowa', '0', 'dzielo', 'kukulowo', '0625', '...  umowa_o_dzielo   \n",
       "10825  ['umowa', 'odiflo', 'zawrzeć', 'dzień', '20221...  umowa_o_dzielo   \n",
       "10826  ['uowaodiflo', 'zawrzeć', 'dzień', '2020032', ...  umowa_o_dzielo   \n",
       "10827  ['umowa', '0', 'dziłlo', 'zawrzeć', 'dzień', '...  umowa_o_dzielo   \n",
       "10828  ['umowa', '0', 'dzieło', 'zawrzeć', 'dzień', '...  umowa_o_dzielo   \n",
       "\n",
       "      language  \n",
       "0           en  \n",
       "1           en  \n",
       "2           en  \n",
       "3           en  \n",
       "4           en  \n",
       "...        ...  \n",
       "10824       pl  \n",
       "10825       pl  \n",
       "10826       pl  \n",
       "10827       pl  \n",
       "10828       pl  \n",
       "\n",
       "[10829 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = pd.read_csv('C:\\\\Users\\\\Janek\\\\Downloads\\\\df_train_preprocessed.csv')\n",
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a2c1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autocorrect import Speller\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    def preprocess_text(self, text_col, lemmatize=False):\n",
    "        self.df[text_col] = self.df[text_col].apply(lambda x: str(x))\n",
    "        self.convert_text_to_lowercase_and_remove_punctation(text_col)\n",
    "        self.detect_language(text_col)\n",
    "        # self.autocorrect_words(text_col)\n",
    "        if lemmatize:\n",
    "            self.remove_stopwords_column(text_col)\n",
    "            self.lemmatize_column(text_col)\n",
    "\n",
    "    def preprocess_image(self, image_col):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def detect_language(self, text_col: str):\n",
    "        def _detect_with_ignore(text: str):\n",
    "            try:\n",
    "                lang = detect(text)\n",
    "            except:\n",
    "                lang = 'en'\n",
    "            return lang\n",
    "\n",
    "        self.df['language'] = self.df[text_col].apply(lambda x: _detect_with_ignore(x))\n",
    "\n",
    "    def convert_text_to_lowercase_and_remove_punctation(self, text_col: str):\n",
    "        def remove_punctuation(text):\n",
    "            punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~=+'''\n",
    "            for ele in text:\n",
    "                if ele in punc:\n",
    "                    text = text.replace(ele, \"\")\n",
    "            return text\n",
    "        self.df[text_col] = self.df[text_col].str.lower()\n",
    "        self.df[text_col] = self.df[text_col].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "    def autocorrect_words(self, text_col: str):\n",
    "        languages = set(self.df['language'])\n",
    "        for lang in languages:\n",
    "            try:\n",
    "                spell = Speller(lang=lang, only_replacements=True)\n",
    "            except:\n",
    "                spell = Speller(lang='en', only_replacements=True)\n",
    "            self.df[text_col] = np.where(self.df['language'] == lang, self.df[text_col].apply(lambda x: spell(x)),\n",
    "                                         self.df[text_col])\n",
    "\n",
    "    def remove_stopwords_column(self, text_col):\n",
    "        self.df[text_col] = self.df.apply(\n",
    "            lambda row: self.remove_stopwords(text=row[text_col], language=row['language']),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    def remove_stopwords(self, text, language='en'):\n",
    "        if language == 'pl':\n",
    "            with open('../../data/stopwords/stop_words_polish.txt', 'r', encoding='utf-8') as file:\n",
    "                content = file.readlines()\n",
    "                content = [line.strip() for line in content]\n",
    "                stop_words = set(content)\n",
    "        else:\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        return ' '.join(filtered_sentence)\n",
    "\n",
    "\n",
    "\n",
    "    def lemmatize_column(self, text_col):\n",
    "        self.df[text_col] = self.df.apply(\n",
    "            lambda row: self.lemmatize_text(text=row[text_col], language=row['language']),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    def lemmatize_text(self, text, language='en'):\n",
    "        if language == \"pl\":\n",
    "            nlp = spacy.load(\"pl_core_news_sm\")\n",
    "        else:\n",
    "            nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc = nlp(text)\n",
    "        return str([token.lemma_ for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "426d7e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    df = pd.DataFrame({'Text': [text]})\n",
    "    preprocessor = Preprocessor(df)\n",
    "    preprocessor.preprocess_text('Text', lemmatize=True)\n",
    "    df_preprocessed = preprocessor.df\n",
    "    return df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9349d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='dsie a dsfajJSJF FJSF j!=d=sa'\n",
    "df = pd.DataFrame({'Text': [text]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7d04d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['dsie', 'dsfajjsjf', 'fjsf', 'jdsa']</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Text language\n",
       "0  ['dsie', 'dsfajjsjf', 'fjsf', 'jdsa']       da"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c506bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa=Preprocessor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5f074c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa.preprocess_text('Text', lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d8070e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['dsie', 'dsfajjsjf', 'fjsf', 'jdsa']</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Text language\n",
       "0  ['dsie', 'dsfajjsjf', 'fjsf', 'jdsa']       da"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2723e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "df_preprocessed['Category'] = Encoder.fit_transform(df_preprocessed['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60cc3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bb995ead-f65c-43e8-9d7f-771546d21651.tiff</td>\n",
       "      <td>['parliament', 'wsrdd', 'scrambeer', 'engeyi',...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2a476c78-ce1c-4535-831c-626635b69fef.tiff</td>\n",
       "      <td>['gilvvmather', 'insertion', 'order', 'i6ken7n...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7bbd6936-4f3d-4eb4-bb75-983cbca08f48.tiff</td>\n",
       "      <td>['newport', '902', 'cosmopolitan', 'april', '1...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62d852b8-25eb-48e0-8cfe-0091c4f2453e.tiff</td>\n",
       "      <td>['goforthegołd', 'introduce', 'true', 'gqld', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8c5a5c2b-c58d-4f7e-985d-236bcc69011e.tiff</td>\n",
       "      <td>['what', 's', 'tobacoo', 'induisty', 'dong', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10824</th>\n",
       "      <td>10824</td>\n",
       "      <td>3827a69b-52cb-4600-a970-5163322ac4d7.jpg</td>\n",
       "      <td>['umowa', '0', 'dzielo', 'kukulowo', '0625', '...</td>\n",
       "      <td>19</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>10825</td>\n",
       "      <td>671cca7a-fe43-4743-9c23-4c4a4ef5b810.jpg</td>\n",
       "      <td>['umowa', 'odiflo', 'zawrzeć', 'dzień', '20221...</td>\n",
       "      <td>19</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10826</th>\n",
       "      <td>10826</td>\n",
       "      <td>a09e8f97-35c0-4327-9ab8-dfc2b2052722.jpg</td>\n",
       "      <td>['uowaodiflo', 'zawrzeć', 'dzień', '2020032', ...</td>\n",
       "      <td>19</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10827</th>\n",
       "      <td>10827</td>\n",
       "      <td>42ede5e5-8b9c-48d7-8996-ca81e8408b90.jpg</td>\n",
       "      <td>['umowa', '0', 'dziłlo', 'zawrzeć', 'dzień', '...</td>\n",
       "      <td>19</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>10828</td>\n",
       "      <td>c76876e7-1df3-4e1e-8898-cbdb7d44df72.jpg</td>\n",
       "      <td>['umowa', '0', 'dzieło', 'zawrzeć', 'dzień', '...</td>\n",
       "      <td>19</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10829 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                       File  \\\n",
       "0               0  bb995ead-f65c-43e8-9d7f-771546d21651.tiff   \n",
       "1               1  2a476c78-ce1c-4535-831c-626635b69fef.tiff   \n",
       "2               2  7bbd6936-4f3d-4eb4-bb75-983cbca08f48.tiff   \n",
       "3               3  62d852b8-25eb-48e0-8cfe-0091c4f2453e.tiff   \n",
       "4               4  8c5a5c2b-c58d-4f7e-985d-236bcc69011e.tiff   \n",
       "...           ...                                        ...   \n",
       "10824       10824   3827a69b-52cb-4600-a970-5163322ac4d7.jpg   \n",
       "10825       10825   671cca7a-fe43-4743-9c23-4c4a4ef5b810.jpg   \n",
       "10826       10826   a09e8f97-35c0-4327-9ab8-dfc2b2052722.jpg   \n",
       "10827       10827   42ede5e5-8b9c-48d7-8996-ca81e8408b90.jpg   \n",
       "10828       10828   c76876e7-1df3-4e1e-8898-cbdb7d44df72.jpg   \n",
       "\n",
       "                                                    Text  Category language  \n",
       "0      ['parliament', 'wsrdd', 'scrambeer', 'engeyi',...         0       en  \n",
       "1      ['gilvvmather', 'insertion', 'order', 'i6ken7n...         0       en  \n",
       "2      ['newport', '902', 'cosmopolitan', 'april', '1...         0       en  \n",
       "3      ['goforthegołd', 'introduce', 'true', 'gqld', ...         0       en  \n",
       "4      ['what', 's', 'tobacoo', 'induisty', 'dong', '...         0       en  \n",
       "...                                                  ...       ...      ...  \n",
       "10824  ['umowa', '0', 'dzielo', 'kukulowo', '0625', '...        19       pl  \n",
       "10825  ['umowa', 'odiflo', 'zawrzeć', 'dzień', '20221...        19       pl  \n",
       "10826  ['uowaodiflo', 'zawrzeć', 'dzień', '2020032', ...        19       pl  \n",
       "10827  ['umowa', '0', 'dziłlo', 'zawrzeć', 'dzień', '...        19       pl  \n",
       "10828  ['umowa', '0', 'dzieło', 'zawrzeć', 'dzień', '...        19       pl  \n",
       "\n",
       "[10829 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2f07e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_val = train_test_split(df_preprocessed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49a2aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['Text']\n",
    "y_train = df_train['Category']\n",
    "X_val = df_val['Text']\n",
    "y_val = df_val['Category']\n",
    "X_train_tokens= [str(word_tokenize(entry)) for entry in X_train]\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(X_train_tokens)\n",
    "Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
    "Val_X_Tfidf = Tfidf_vect.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665cf3a0",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cb00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline_bayes(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\n",
    "    Naive = naive_bayes.MultinomialNB()\n",
    "    Naive.fit(Train_X_Tfidf, y_train)\n",
    "    predictions_NB = Naive.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_NB, y_val)\n",
    "    f1 = f1_score(predictions_NB, y_val, average='macro')\n",
    "    print(\"Naive Bayes Accuracy Score:\", accuracy * 100)\n",
    "    print(\"Naive Bayes F1 Score:\", f1 * 100)\n",
    "    return predictions_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56e52667",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "training_pipeline_bayes() missing 1 required positional argument: 'y_val'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24848/382412067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_pipeline_bayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_X_Tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVal_X_Tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: training_pipeline_bayes() missing 1 required positional argument: 'y_val'"
     ]
    }
   ],
   "source": [
    "training_pipeline_bayes(Train_X_Tfidf, Val_X_Tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2b594",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21aa0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline_svm(df_train, df_val):\n",
    "    X_train = df_train['Text']\n",
    "    y_train = df_train['Category']\n",
    "    X_val = df_val['Text']\n",
    "    y_val = df_val['Category']\n",
    "    X_train_tokens= [str(word_tokenize(entry)) for entry in X_train]\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "    Tfidf_vect.fit(X_train_tokens)\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
    "    Val_X_Tfidf = Tfidf_vect.transform(X_val)\n",
    "    SVM = svm.SVC(C=10, gamma='scale', kernel='rbf')\n",
    "    SVM.fit(Train_X_Tfidf,y_train)\n",
    "    predictions_SVM = SVM.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_SVM, y_val)\n",
    "    f1 = f1_score(predictions_SVM, y_val, average='macro')\n",
    "    precision = precision_score(predictions_SVM, y_val, average='macro')\n",
    "    recall = recall_score(predictions_SVM, y_val, average='macro')\n",
    "    confusion_mat = confusion_matrix(predictions_SVM, y_val)\n",
    "    confusion_df = pd.DataFrame(confusion_mat, columns=np.unique(y_val), index=np.unique(y_val))\n",
    "    print(\"SVM Accuracy Score:\", accuracy * 100)\n",
    "    print(\"SVM:\", f1 * 100)\n",
    "    print(\"SVM Precision:\", precision * 100)\n",
    "    print(\"SVM Recall:\", recall * 100)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_df)\n",
    "    return predictions_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc9ba120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score: 73.08402585410896\n",
      "SVM: 75.78342606923688\n",
      "SVM Precision: 75.60363359300449\n",
      "SVM Recall: 77.09002753157172\n",
      "Confusion Matrix:\n",
      "    0   1   2   3   4    5   6   7   8   9   ...  11  12  13   14  15  16  17  \\\n",
      "0   51   0   1   4   0    8   1   2   0   3  ...   0   7   2    0   0   7   0   \n",
      "1    6  67   3   2   5    1  12   0   2   5  ...   0   5   4    0   0   6   2   \n",
      "2    1   0  91   0   0    0   0   1   3   0  ...   0   3   0    0   0   0   0   \n",
      "3   13   5   1  89   1    9   0   1   0   4  ...   0   8   0    0   1   3   2   \n",
      "4    3   3   1   0  60    1   4   6   2   0  ...   0   2   3    0   0   8   2   \n",
      "5   25   4   1   7   8  102  10   4   3  14  ...   0   9  13    1   3  11  11   \n",
      "6    1  10   0   0   5    1  77   3   1   1  ...   0   2   2    1   0   2   1   \n",
      "7    1   0   4   0   2    1   0  66   7   1  ...   0   4   4    0   0   4   0   \n",
      "8    0   3   6   1   2    0   1  16  72   1  ...   0   3   3    1   0   4   1   \n",
      "9    6   2   0   1   0    0   0   2   0  69  ...   0   8   4    1   7   0   0   \n",
      "10   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "11   0   0   0   0   0    0   0   0   0   0  ...  58   0   0    0   0   0   0   \n",
      "12  12   8   2   2   3    1   4   1   4   5  ...   0  64   1    0   0   4   0   \n",
      "13   4   1   0   0   4    1   0   0   0   1  ...   0   1  58    0   0   1   0   \n",
      "14   0   0   0   0   0    0   0   1   0   0  ...   0   1   0  111   0   1   0   \n",
      "15   1   0   0   0   1    0   0   3   0   2  ...   0   1   0    1  97  11   0   \n",
      "16   2   1   1   2   7    3   5   6   5   0  ...   0  12   2    3   7  63   4   \n",
      "17   0   0   0   0   4    0   0   0   0   0  ...   0   0   0    0   0   2  85   \n",
      "18   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "19   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "20   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "\n",
      "    18  19  20  \n",
      "0    0   0   0  \n",
      "1    0   0   0  \n",
      "2    0   0   0  \n",
      "3    0   0   0  \n",
      "4    0   0   0  \n",
      "5    0   0   0  \n",
      "6    0   0   0  \n",
      "7    0   0   0  \n",
      "8    0   0   0  \n",
      "9    0   0   0  \n",
      "10   0   0   0  \n",
      "11   0   0   0  \n",
      "12   0   0   0  \n",
      "13   0   0   0  \n",
      "14   0   0   0  \n",
      "15   0   0   0  \n",
      "16   0   0   0  \n",
      "17   0   0   0  \n",
      "18  71   0   0  \n",
      "19   0  81   0  \n",
      "20   0   0  64  \n",
      "\n",
      "[21 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6,  3,  5, ..., 16, 10,  5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_svm(df_train, df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2ca56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def training_pipeline_svm(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\n",
    "    parameters = {'C': [1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "    SVM = svm.SVC()\n",
    "    grid_search = GridSearchCV(SVM, parameters, cv=5)\n",
    "    grid_search.fit(Train_X_Tfidf, y_train)\n",
    "    \n",
    "    best_SVM = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    best_SVM.fit(Train_X_Tfidf, y_train)\n",
    "    predictions_SVM = best_SVM.predict(Val_X_Tfidf)\n",
    "    \n",
    "    accuracy = accuracy_score(predictions_SVM, y_val)\n",
    "    f1 = f1_score(predictions_SVM, y_val, average='macro')\n",
    "    precision = precision_score(predictions_SVM, y_val, average='macro')\n",
    "    recall = recall_score(predictions_SVM, y_val, average='macro')\n",
    "    confusion_mat = confusion_matrix(predictions_SVM, y_val)\n",
    "    confusion_df = pd.DataFrame(confusion_mat, columns=np.unique(y_val), index=np.unique(y_val))\n",
    "    \n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"SVM Accuracy Score:\", accuracy * 100)\n",
    "    print(\"SVM F1 Score:\", f1 * 100)\n",
    "    print(\"SVM Precision:\", precision * 100)\n",
    "    print(\"SVM Recall:\", recall * 100)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_df)\n",
    "    \n",
    "    return predictions_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "288b5c51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM Accuracy Score: 73.08402585410896\n",
      "SVM F1 Score: 75.78342606923688\n",
      "SVM Precision: 75.60363359300449\n",
      "SVM Recall: 77.09002753157172\n",
      "Confusion Matrix:\n",
      "    0   1   2   3   4    5   6   7   8   9   ...  11  12  13   14  15  16  17  \\\n",
      "0   51   0   1   4   0    8   1   2   0   3  ...   0   7   2    0   0   7   0   \n",
      "1    6  67   3   2   5    1  12   0   2   5  ...   0   5   4    0   0   6   2   \n",
      "2    1   0  91   0   0    0   0   1   3   0  ...   0   3   0    0   0   0   0   \n",
      "3   13   5   1  89   1    9   0   1   0   4  ...   0   8   0    0   1   3   2   \n",
      "4    3   3   1   0  60    1   4   6   2   0  ...   0   2   3    0   0   8   2   \n",
      "5   25   4   1   7   8  102  10   4   3  14  ...   0   9  13    1   3  11  11   \n",
      "6    1  10   0   0   5    1  77   3   1   1  ...   0   2   2    1   0   2   1   \n",
      "7    1   0   4   0   2    1   0  66   7   1  ...   0   4   4    0   0   4   0   \n",
      "8    0   3   6   1   2    0   1  16  72   1  ...   0   3   3    1   0   4   1   \n",
      "9    6   2   0   1   0    0   0   2   0  69  ...   0   8   4    1   7   0   0   \n",
      "10   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "11   0   0   0   0   0    0   0   0   0   0  ...  58   0   0    0   0   0   0   \n",
      "12  12   8   2   2   3    1   4   1   4   5  ...   0  64   1    0   0   4   0   \n",
      "13   4   1   0   0   4    1   0   0   0   1  ...   0   1  58    0   0   1   0   \n",
      "14   0   0   0   0   0    0   0   1   0   0  ...   0   1   0  111   0   1   0   \n",
      "15   1   0   0   0   1    0   0   3   0   2  ...   0   1   0    1  97  11   0   \n",
      "16   2   1   1   2   7    3   5   6   5   0  ...   0  12   2    3   7  63   4   \n",
      "17   0   0   0   0   4    0   0   0   0   0  ...   0   0   0    0   0   2  85   \n",
      "18   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "19   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "20   0   0   0   0   0    0   0   0   0   0  ...   0   0   0    0   0   0   0   \n",
      "\n",
      "    18  19  20  \n",
      "0    0   0   0  \n",
      "1    0   0   0  \n",
      "2    0   0   0  \n",
      "3    0   0   0  \n",
      "4    0   0   0  \n",
      "5    0   0   0  \n",
      "6    0   0   0  \n",
      "7    0   0   0  \n",
      "8    0   0   0  \n",
      "9    0   0   0  \n",
      "10   0   0   0  \n",
      "11   0   0   0  \n",
      "12   0   0   0  \n",
      "13   0   0   0  \n",
      "14   0   0   0  \n",
      "15   0   0   0  \n",
      "16   0   0   0  \n",
      "17   0   0   0  \n",
      "18  71   0   0  \n",
      "19   0  81   0  \n",
      "20   0   0  64  \n",
      "\n",
      "[21 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6,  3,  5, ..., 16, 10,  5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_svm(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5fa190",
   "metadata": {},
   "source": [
    "bezbledna predykcja:\n",
    "- umowa_sprzedazy_samochodu \n",
    "- umowa_o_dzielo \n",
    "- umowa_na_odleglosc_odstapienie \n",
    "- pozwolenie_uzytkowanie_obiektu_budowlanego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebf463",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def training_pipeline_xgb(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):  \n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_model.fit(Train_X_Tfidf, y_train)\n",
    "    \n",
    "    predictions_xgb = xgb_model.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_xgb, y_val)\n",
    "    f1 = f1_score(predictions_xgb, y_val, average='macro')\n",
    "    \n",
    "    print(\"XGBoost Accuracy Score:\", accuracy * 100)\n",
    "    print(\"XGBoost F1 Score:\", f1 * 100)\n",
    "    \n",
    "    return predictions_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e84be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline_xgb(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59858267",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1098513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def training_pipeline_linear(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):  \n",
    "    linear_model = LinearSVC()\n",
    "    linear_model.fit(Train_X_Tfidf, y_train)\n",
    "    \n",
    "    predictions_linear = linear_model.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_linear, y_val)\n",
    "    f1 = f1_score(predictions_linear, y_val, average='macro')\n",
    "    \n",
    "    print(\"Linear Classifier Accuracy Score:\", accuracy * 100)\n",
    "    print(\"Linear Classifier F1 Score:\", f1 * 100)\n",
    "    \n",
    "    return predictions_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75087380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier Accuracy Score: 71.37580794090489\n",
      "Linear Classifier F1 Score: 73.74887330222634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6,  3,  3, ..., 14, 10,  6])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_linear(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63451c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ce807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def training_pipeline_rf(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(Train_X_Tfidf, y_train)\n",
    "    \n",
    "    predictions_rf = rf_model.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_rf, y_val)\n",
    "    f1 = f1_score(predictions_rf, y_val, average='macro')\n",
    "    \n",
    "    print(\"Random Forest Accuracy Score:\", accuracy * 100)\n",
    "    print(\"Random Forest F1 Score:\", f1 * 100)\n",
    "    \n",
    "    return predictions_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e18ae60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score: 69.62142197599262\n",
      "Random Forest F1 Score: 72.21017976314799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4,  3,  3, ..., 14, 10,  5])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_rf(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d901c2",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84e4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def training_pipeline_lr(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\n",
    "    LR = LogisticRegression()\n",
    "    LR.fit(Train_X_Tfidf, y_train)\n",
    "    predictions_LR = LR.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_LR, y_val)\n",
    "    f1 = f1_score(predictions_LR, y_val, average='macro')\n",
    "    precision = precision_score(predictions_LR, y_val, average='macro')\n",
    "    recall = recall_score(predictions_LR, y_val, average='macro')\n",
    "    confusion_mat = confusion_matrix(predictions_LR, y_val)\n",
    "    \n",
    "    # Convert confusion matrix to DataFrame for better visualization\n",
    "    confusion_df = pd.DataFrame(confusion_mat, columns=np.unique(y_val), index=np.unique(y_val))\n",
    "    \n",
    "    print(\"Logistic Regression Accuracy Score:\", accuracy * 100)\n",
    "    print(\"Logistic Regression F1 Score:\", f1 * 100)\n",
    "    print(\"Logistic Regression Precision:\", precision * 100)\n",
    "    print(\"Logistic Regression Recall:\", recall * 100)\n",
    "    \n",
    "    return predictions_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4373bb85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_24848/2363693903.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Janek\\AppData\\Local\\Temp/ipykernel_24848/2363693903.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    training_pipeline_lr(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "training_pipeline_lr(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc9783",
   "metadata": {},
   "source": [
    "# Top 2 logistic regression i SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
