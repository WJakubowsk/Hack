{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c502342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6969ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bb995ead-f65c-43e8-9d7f-771546d21651.tiff</td>\n",
       "      <td>['parliament', 'wsrdd', 'scrambeer', 'engeyi',...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2a476c78-ce1c-4535-831c-626635b69fef.tiff</td>\n",
       "      <td>['gilvvmather', 'insertion', 'order', 'i6ken7n...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7bbd6936-4f3d-4eb4-bb75-983cbca08f48.tiff</td>\n",
       "      <td>['newport', '902', 'cosmopolitan', 'april', '1...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62d852b8-25eb-48e0-8cfe-0091c4f2453e.tiff</td>\n",
       "      <td>['goforthegołd', 'introduce', 'true', 'gqld', ...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8c5a5c2b-c58d-4f7e-985d-236bcc69011e.tiff</td>\n",
       "      <td>['what', 's', 'tobacoo', 'induisty', 'dong', '...</td>\n",
       "      <td>advertisement</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10824</th>\n",
       "      <td>10824</td>\n",
       "      <td>3827a69b-52cb-4600-a970-5163322ac4d7.jpg</td>\n",
       "      <td>['umowa', '0', 'dzielo', 'kukulowo', '0625', '...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>10825</td>\n",
       "      <td>671cca7a-fe43-4743-9c23-4c4a4ef5b810.jpg</td>\n",
       "      <td>['umowa', 'odiflo', 'zawrzeć', 'dzień', '20221...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10826</th>\n",
       "      <td>10826</td>\n",
       "      <td>a09e8f97-35c0-4327-9ab8-dfc2b2052722.jpg</td>\n",
       "      <td>['uowaodiflo', 'zawrzeć', 'dzień', '2020032', ...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10827</th>\n",
       "      <td>10827</td>\n",
       "      <td>42ede5e5-8b9c-48d7-8996-ca81e8408b90.jpg</td>\n",
       "      <td>['umowa', '0', 'dziłlo', 'zawrzeć', 'dzień', '...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>10828</td>\n",
       "      <td>c76876e7-1df3-4e1e-8898-cbdb7d44df72.jpg</td>\n",
       "      <td>['umowa', '0', 'dzieło', 'zawrzeć', 'dzień', '...</td>\n",
       "      <td>umowa_o_dzielo</td>\n",
       "      <td>pl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10829 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                       File  \\\n",
       "0               0  bb995ead-f65c-43e8-9d7f-771546d21651.tiff   \n",
       "1               1  2a476c78-ce1c-4535-831c-626635b69fef.tiff   \n",
       "2               2  7bbd6936-4f3d-4eb4-bb75-983cbca08f48.tiff   \n",
       "3               3  62d852b8-25eb-48e0-8cfe-0091c4f2453e.tiff   \n",
       "4               4  8c5a5c2b-c58d-4f7e-985d-236bcc69011e.tiff   \n",
       "...           ...                                        ...   \n",
       "10824       10824   3827a69b-52cb-4600-a970-5163322ac4d7.jpg   \n",
       "10825       10825   671cca7a-fe43-4743-9c23-4c4a4ef5b810.jpg   \n",
       "10826       10826   a09e8f97-35c0-4327-9ab8-dfc2b2052722.jpg   \n",
       "10827       10827   42ede5e5-8b9c-48d7-8996-ca81e8408b90.jpg   \n",
       "10828       10828   c76876e7-1df3-4e1e-8898-cbdb7d44df72.jpg   \n",
       "\n",
       "                                                    Text        Category  \\\n",
       "0      ['parliament', 'wsrdd', 'scrambeer', 'engeyi',...   advertisement   \n",
       "1      ['gilvvmather', 'insertion', 'order', 'i6ken7n...   advertisement   \n",
       "2      ['newport', '902', 'cosmopolitan', 'april', '1...   advertisement   \n",
       "3      ['goforthegołd', 'introduce', 'true', 'gqld', ...   advertisement   \n",
       "4      ['what', 's', 'tobacoo', 'induisty', 'dong', '...   advertisement   \n",
       "...                                                  ...             ...   \n",
       "10824  ['umowa', '0', 'dzielo', 'kukulowo', '0625', '...  umowa_o_dzielo   \n",
       "10825  ['umowa', 'odiflo', 'zawrzeć', 'dzień', '20221...  umowa_o_dzielo   \n",
       "10826  ['uowaodiflo', 'zawrzeć', 'dzień', '2020032', ...  umowa_o_dzielo   \n",
       "10827  ['umowa', '0', 'dziłlo', 'zawrzeć', 'dzień', '...  umowa_o_dzielo   \n",
       "10828  ['umowa', '0', 'dzieło', 'zawrzeć', 'dzień', '...  umowa_o_dzielo   \n",
       "\n",
       "      language  \n",
       "0           en  \n",
       "1           en  \n",
       "2           en  \n",
       "3           en  \n",
       "4           en  \n",
       "...        ...  \n",
       "10824       pl  \n",
       "10825       pl  \n",
       "10826       pl  \n",
       "10827       pl  \n",
       "10828       pl  \n",
       "\n",
       "[10829 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = pd.read_csv('C:\\\\Users\\\\Janek\\\\Downloads\\\\df_train_preprocessed.csv')\n",
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4372332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "df_preprocessed['Category'] = Encoder.fit_transform(df_preprocessed['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1238dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called 'df' with a 'language' column\n",
    "\n",
    "# Create 'df_pl' by selecting rows where 'language' is 'pl'\n",
    "df_pl = df_preprocessed[df_preprocessed['language'] == 'pl'].copy()\n",
    "\n",
    "# Create 'df_en' by selecting rows where 'language' is not 'pl'\n",
    "df_en = df_preprocessed[df_preprocessed['language'] != 'pl'].copy()\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "df_pl.reset_index(drop=True, inplace=True)\n",
    "df_en.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd8bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_en_val = train_test_split(df_en, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbffa49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_train = df_en_train['Text']\n",
    "y_en_train = df_en_train['Category']\n",
    "X_en_val = df_en_val['Text']\n",
    "y_en_val = df_en_val['Category']\n",
    "X_en_train_tokens= [str(word_tokenize(entry)) for entry in X_en_train]\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(X_en_train_tokens)\n",
    "Train_X_Tfidf = Tfidf_vect.transform(X_en_train)\n",
    "Val_X_Tfidf = Tfidf_vect.transform(X_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c8799bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pl_train = df_pl_train['Text']\n",
    "y_pl_train = df_pl_train['Category']\n",
    "X_pl_val = df_pl_val['Text']\n",
    "y_pl_val = df_pl_val['Category']\n",
    "X_pl_train_tokens= [str(word_tokenize(entry)) for entry in X_pl_train]\n",
    "Tfidf_vect_pl = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect_pl.fit(X_pl_train_tokens)\n",
    "Train_X_Tfidf_pl = Tfidf_vect_pl.transform(X_pl_train)\n",
    "Val_X_Tfidf_pl = Tfidf_vect_pl.transform(X_pl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693cf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline_svm(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "    SVM.fit(Train_X_Tfidf,y_train)\n",
    "    predictions_SVM = SVM.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_SVM, y_val)\n",
    "    f1 = f1_score(predictions_SVM, y_val, average='macro')\n",
    "    precision = precision_score(predictions_SVM, y_val, average='macro')\n",
    "    recall = recall_score(predictions_SVM, y_val, average='macro')\n",
    "    confusion_mat = confusion_matrix(predictions_SVM, y_val)\n",
    "    confusion_df = pd.DataFrame(confusion_mat, columns=np.unique(y_val), index=np.unique(y_val))\n",
    "    print(\"SVM Accuracy Score:\", accuracy * 100)\n",
    "    print(\"SVM:\", f1 * 100)\n",
    "    print(\"SVM Precision:\", precision * 100)\n",
    "    print(\"SVM Recall:\", recall * 100)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_df)\n",
    "    return predictions_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a7e4505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score: 66.90929451287793\n",
      "SVM: 67.33923910829989\n",
      "SVM Precision: 66.93551315588063\n",
      "SVM Recall: 69.67641489974432\n",
      "Confusion Matrix:\n",
      "    0   1    2   3   4   5   6   7   8   9   12  13   14   15  16  17\n",
      "0   77   8    2   1   0   9   1   5   2   4   5   3    0    0   4   3\n",
      "1    1  63    2   1   2   2  11   0   2   2   8   3    0    2   2   4\n",
      "2    0   1  100   0   2   1   0   2   4   1   2   0    0    0   1   0\n",
      "3   17   8    2  92   3  21   4   6   3   6  18   5    2    3   9   4\n",
      "4    4   0    3   1  52   1   4   6   4   0   0   2    0    0   3   2\n",
      "5   12   5    0   1   5  75   5   7   3   8   4  10    0    2   9   9\n",
      "6    1   2    0   1   2   3  50   4   2   1   2   1    0    0   2   1\n",
      "7    0   0    1   0   1   1   2  65   8   0   3   3    0    0   1   0\n",
      "8    2   3    5   0  13   0   0  17  66   0   2   4    0    0   8   2\n",
      "9    6   3    5   0   0   1   0   3   0  70   6   3    1    6   2   0\n",
      "12   5   8    2   5   4   3   3   3   3   7  60   5    1    4   7   2\n",
      "13   0   0    2   0   4   1   0   1   1   0   1  71    0    1   0   1\n",
      "14   0   1    0   0   0   0   0   0   0   1   1   0  100    0   0   0\n",
      "15   0   0    0   0   0   0   0   0   0   3   1   0    0  101   4   0\n",
      "16   2   3    1   2   9   3   4   5   2   1   2   1    1    5  72   3\n",
      "17   0   0    0   0   3   0   0   0   0   0   0   1    0    0   0  81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  4, ...,  3, 16,  2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_svm(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa774a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score: 98.15789473684211\n",
      "SVM: 64.63560334528077\n",
      "SVM Precision: 62.03703703703704\n",
      "SVM Recall: 71.8694885361552\n",
      "Confusion Matrix:\n",
      "    3   5   6   10  11  12  18  19  20\n",
      "3    0   2   2   0   0   0   0   0   0\n",
      "5    0   1   0   0   0   0   0   0   0\n",
      "6    0   0   1   0   0   1   0   0   0\n",
      "10   0   0   0  89   0   0   0   0   0\n",
      "11   0   0   0   0  60   0   0   0   0\n",
      "12   0   0   0   0   0   0   0   0   0\n",
      "18   1   0   1   0   0   0  61   0   0\n",
      "19   0   0   0   0   0   0   0  76   0\n",
      "20   0   0   0   0   0   0   0   0  85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janek\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20, 10, 11, 11, 20, 18, 10, 10, 20, 18, 19, 19, 10, 10, 10, 19, 18,\n",
       "       20, 10, 20, 20, 10, 19, 11, 19, 11, 10, 19, 20, 18, 20, 19, 19, 20,\n",
       "       19, 20, 18, 18, 11, 10, 18, 18, 11, 20, 19, 20, 10, 20, 10, 20, 20,\n",
       "       11, 18, 18, 11, 18, 11, 18, 10, 20, 19, 18, 10, 20, 10, 11, 19, 11,\n",
       "       20, 19, 20, 20, 10, 10, 19, 10, 11, 19,  3, 20, 18, 10, 10, 20, 10,\n",
       "       19, 18, 19, 11, 11, 11, 18, 19, 20, 19, 11, 11, 18, 19, 18, 19, 20,\n",
       "       20, 19, 10, 20, 10, 18, 20,  6, 10, 20, 19, 19, 18, 11, 11, 19, 11,\n",
       "       10, 20, 18, 19, 19, 19, 20, 11, 10, 18, 10, 11, 20, 19, 19, 11, 20,\n",
       "       19, 18, 10, 19, 18, 19, 19, 10, 11, 11, 19, 10, 19, 10, 19, 10, 11,\n",
       "       20, 18, 10, 10, 11, 20, 19, 18, 11, 11, 18, 20, 11, 20, 19, 20, 20,\n",
       "       10, 20, 18, 11, 18, 11, 10, 19, 18, 10, 20, 11, 20, 18, 10, 11, 19,\n",
       "       10, 11, 20, 19, 11, 19, 18, 20,  3, 19, 20, 18, 10, 20, 10, 10, 19,\n",
       "       11, 10, 18, 19, 19, 20, 18, 20, 20, 20, 20, 19, 10, 19, 20, 18, 18,\n",
       "       19, 10, 19, 11, 10, 10, 11, 20, 10, 10, 10, 10, 10, 10, 10, 10, 20,\n",
       "       11, 20, 11, 19, 10, 18, 20, 20, 20, 10,  6, 20, 10, 18, 11, 20, 10,\n",
       "       10, 19, 18, 10, 11, 18, 11,  5, 18, 18, 11, 11, 18, 10, 20, 20, 10,\n",
       "       20,  3, 19, 10, 18, 10, 19, 11, 18, 10, 19, 11, 20, 18, 20, 10, 20,\n",
       "       18, 18, 20, 19, 20, 10, 19, 18, 18, 20, 19, 10, 10, 20, 19, 18, 19,\n",
       "       19, 10, 10, 20, 10, 19, 18, 10, 10, 10, 11, 11, 19, 10, 20, 11, 20,\n",
       "       20, 18, 20, 10, 10, 20, 19, 19, 11, 11, 18, 19, 11, 20, 10, 18, 10,\n",
       "       20, 18, 20, 20, 19, 18, 11, 20, 10, 11, 10, 18, 10,  3, 19, 11, 11,\n",
       "       10, 20, 20, 19, 11, 18, 19, 19, 20, 10, 19, 20, 19, 20, 18, 10, 19,\n",
       "       10, 19, 18, 11, 18, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_svm(Train_X_Tfidf_pl, Val_X_Tfidf_pl, y_pl_train, y_pl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665cf3a0",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6df4077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline_bayes(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\n",
    "    Naive = naive_bayes.MultinomialNB()\n",
    "    Naive.fit(Train_X_Tfidf, y_train)\n",
    "    predictions_NB = Naive.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_NB, y_val)\n",
    "    f1 = f1_score(predictions_NB, y_val, average='macro')\n",
    "    precision = precision_score(predictions_NB, y_val, average='macro')\n",
    "    recall = recall_score(predictions_NB, y_val, average='macro')\n",
    "    print(\"Naive Bayes Accuracy Score:\", accuracy * 100)\n",
    "    print(\"Naive Bayes F1 Score:\", f1 * 100)\n",
    "    print(\"Naive Bayes Precision:\", precision * 100)\n",
    "    print(\"Naive Bayes Recall:\", recall * 100)\n",
    "    return predictions_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f160a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score: 61.03023516237403\n",
      "Naive Bayes F1 Score: 59.9368183149972\n",
      "Naive Bayes Precision: 60.98390565838439\n",
      "Naive Bayes Recall: 67.11620324065647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  4, 16, ...,  5, 16,  2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_bayes(Train_X_Tfidf, Val_X_Tfidf, y_en_train, y_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09ccd4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score: 97.63157894736842\n",
      "Naive Bayes F1 Score: 54.91595719271177\n",
      "Naive Bayes Precision: 55.55555555555556\n",
      "Naive Bayes Recall: 54.30045699213968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janek\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20, 10, 11, 11, 20, 18, 10, 10, 20, 18, 19, 19, 10, 10, 10, 19, 18,\n",
       "       20, 10, 20, 20, 10, 19, 11, 19, 11, 10, 19, 20, 18, 20, 19, 19, 20,\n",
       "       19, 20, 18, 18, 11, 10, 18, 18, 11, 20, 19, 20, 10, 20, 10, 20, 20,\n",
       "       11, 18, 18, 11, 18, 11, 18, 10, 20, 19, 18, 10, 20, 10, 11, 19, 11,\n",
       "       20, 19, 20, 20, 10, 10, 19, 10, 11, 19, 20, 20, 18, 10, 10, 20, 10,\n",
       "       19, 18, 19, 11, 11, 11, 18, 19, 20, 19, 11, 11, 18, 19, 18, 19, 20,\n",
       "       20, 19, 10, 20, 10, 18, 20, 10, 10, 20, 19, 19, 18, 11, 11, 19, 11,\n",
       "       10, 20, 18, 19, 19, 19, 20, 11, 10, 18, 10, 11, 20, 19, 19, 11, 20,\n",
       "       19, 18, 10, 19, 18, 19, 19, 10, 11, 11, 19, 10, 19, 10, 19, 10, 11,\n",
       "       20, 18, 10, 10, 11, 20, 19, 18, 11, 11, 18, 20, 11, 20, 19, 20, 20,\n",
       "       10, 20, 18, 11, 18, 11, 10, 19, 18, 10, 20, 11, 20, 18, 10, 11, 19,\n",
       "       10, 11, 20, 19, 11, 19, 18, 20, 10, 19, 20, 18, 10, 20, 10, 10, 19,\n",
       "       11, 10, 18, 19, 19, 20, 18, 20, 20, 20, 20, 19, 10, 19, 20, 18, 18,\n",
       "       19, 10, 19, 11, 10, 10, 11, 20, 10, 10, 10, 10, 10, 10, 10, 10, 20,\n",
       "       11, 20, 11, 19, 10, 18, 20, 20, 20, 10, 10, 20, 10, 18, 11, 20, 10,\n",
       "       10, 19, 18, 10, 11, 18, 11, 10, 18, 18, 11, 11, 18, 10, 20, 20, 10,\n",
       "       20, 10, 19, 10, 18, 10, 19, 11, 18, 10, 19, 11, 20, 18, 20, 10, 20,\n",
       "       18, 18, 20, 19, 20, 10, 19, 18, 18, 20, 19, 10, 10, 20, 19, 18, 19,\n",
       "       19, 10, 10, 20, 10, 19, 18, 10, 10, 10, 11, 11, 19, 10, 20, 11, 20,\n",
       "       20, 18, 20, 10, 10, 20, 19, 19, 11, 11, 18, 19, 11, 20, 10, 18, 10,\n",
       "       20, 18, 20, 20, 19, 18, 11, 20, 10, 11, 10, 18, 10, 11, 19, 11, 11,\n",
       "       10, 20, 20, 19, 11, 18, 19, 19, 20, 10, 19, 20, 19, 20, 18, 10, 19,\n",
       "       10, 19, 18, 11, 18, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_bayes(Train_X_Tfidf_pl, Val_X_Tfidf_pl, y_pl_train, y_pl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d901c2",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a84e4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def training_pipeline_lr(Train_X_Tfidf, Val_X_Tfidf, y_train, y_val):\n",
    "    LR = LogisticRegression()\n",
    "    LR.fit(Train_X_Tfidf, y_train)\n",
    "    predictions_LR = LR.predict(Val_X_Tfidf)\n",
    "    accuracy = accuracy_score(predictions_LR, y_val)\n",
    "    f1 = f1_score(predictions_LR, y_val, average='macro')\n",
    "    precision = precision_score(predictions_LR, y_val, average='macro')\n",
    "    recall = recall_score(predictions_LR, y_val, average='macro')\n",
    "    confusion_mat = confusion_matrix(predictions_LR, y_val)\n",
    "    \n",
    "    # Convert confusion matrix to DataFrame for better visualization\n",
    "    confusion_df = pd.DataFrame(confusion_mat, columns=np.unique(y_val), index=np.unique(y_val))\n",
    "    \n",
    "    print(\"Logistic Regression Accuracy Score:\", accuracy * 100)\n",
    "    print(\"Logistic Regression F1 Score:\", f1 * 100)\n",
    "    print(\"Logistic Regression Precision:\", precision * 100)\n",
    "    print(\"Logistic Regression Recall:\", recall * 100)\n",
    "    \n",
    "    return predictions_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4373bb85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score: 66.90929451287793\n",
      "Logistic Regression F1 Score: 67.3617525714085\n",
      "Logistic Regression Precision: 67.07964365927054\n",
      "Logistic Regression Recall: 69.73853738583497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  4, ...,  3, 16,  2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_lr(Train_X_Tfidf, Val_X_Tfidf, y_en_train, y_en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9d3015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score: 97.63157894736842\n",
      "Logistic Regression F1 Score: 54.871794871794876\n",
      "Logistic Regression Precision: 55.55555555555556\n",
      "Logistic Regression Recall: 54.267310789049915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Janek\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20, 10, 11, 11, 20, 18, 10, 10, 20, 18, 19, 19, 10, 10, 10, 19, 18,\n",
       "       20, 10, 20, 20, 10, 19, 11, 19, 11, 10, 19, 20, 18, 20, 19, 19, 20,\n",
       "       19, 20, 18, 18, 11, 10, 18, 18, 11, 20, 19, 20, 10, 20, 10, 20, 20,\n",
       "       11, 18, 18, 11, 18, 11, 18, 10, 20, 19, 18, 10, 20, 10, 11, 19, 11,\n",
       "       20, 19, 20, 20, 10, 10, 19, 10, 11, 19, 18, 20, 18, 10, 10, 20, 10,\n",
       "       19, 18, 19, 11, 11, 11, 18, 19, 20, 19, 11, 11, 18, 19, 18, 19, 20,\n",
       "       20, 19, 10, 20, 10, 18, 20,  6, 10, 20, 19, 19, 18, 11, 11, 19, 11,\n",
       "       10, 20, 18, 19, 19, 19, 20, 11, 10, 18, 10, 11, 20, 19, 19, 11, 20,\n",
       "       19, 18, 10, 19, 18, 19, 19, 10, 11, 11, 19, 10, 19, 10, 19, 10, 11,\n",
       "       20, 18, 10, 10, 11, 20, 19, 18, 11, 11, 18, 20, 11, 20, 19, 20, 20,\n",
       "       10, 20, 18, 11, 18, 11, 10, 19, 18, 10, 20, 11, 20, 18, 10, 11, 19,\n",
       "       10, 11, 20, 19, 11, 19, 18, 20, 18, 19, 20, 18, 10, 20, 10, 10, 19,\n",
       "       11, 10, 18, 19, 19, 20, 18, 20, 20, 20, 20, 19, 10, 19, 20, 18, 18,\n",
       "       19, 10, 19, 11, 10, 10, 11, 20, 10, 10, 10, 10, 10, 10, 10, 10, 20,\n",
       "       11, 20, 11, 19, 10, 18, 20, 20, 20, 10, 18, 20, 10, 18, 11, 20, 10,\n",
       "       10, 19, 18, 10, 11, 18, 11, 18, 18, 18, 11, 11, 18, 10, 20, 20, 10,\n",
       "       20, 18, 19, 10, 18, 10, 19, 11, 18, 10, 19, 11, 20, 18, 20, 10, 20,\n",
       "       18, 18, 20, 19, 20, 10, 19, 18, 18, 20, 19, 10, 10, 20, 19, 18, 19,\n",
       "       19, 10, 10, 20, 10, 19, 18, 10, 10, 10, 11, 11, 19, 10, 20, 11, 20,\n",
       "       20, 18, 20, 10, 10, 20, 19, 19, 11, 11, 18, 19, 11, 20, 10, 18, 10,\n",
       "       20, 18, 20, 20, 19, 18, 11, 20, 10, 11, 10, 18, 10, 18, 19, 11, 11,\n",
       "       10, 20, 20, 19, 11, 18, 19, 19, 20, 10, 19, 20, 19, 20, 18, 10, 19,\n",
       "       10, 19, 18, 11, 18, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_lr(Train_X_Tfidf_pl, Val_X_Tfidf_pl, y_pl_train, y_pl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fd7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1110b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2dc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c1aa052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "760e780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['text_col']\n",
    "y_train = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24565fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens= [str(word_tokenize(entry)) for entry in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ea69d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens']= (X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbfcabad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['To', 'jest', 'przykładowe', 'zdanie', 'po', ...\n",
       "1    ['This', 'is', 'an', 'example', 'sentence', 'i...\n",
       "2    ['Łatwość', 'korzystania', 'z', 'tego', 'narzę...\n",
       "3    ['The', 'ease', 'of', 'use', 'of', 'this', 'to...\n",
       "4            ['Cześć', '!', 'Jak', 'się', 'masz', '?']\n",
       "5             ['Hello', '!', 'How', 'are', 'you', '?']\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2efb129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>target</th>\n",
       "      <th>final</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To jest przykładowe zdanie po polsku.</td>\n",
       "      <td>1</td>\n",
       "      <td>['Hello', '!', 'How', 'are', 'you', '?']</td>\n",
       "      <td>[To, jest, przykładowe, zdanie, po, polsku, .]</td>\n",
       "      <td>['To', 'jest', 'przykładowe', 'zdanie', 'po', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example sentence in English.</td>\n",
       "      <td>2</td>\n",
       "      <td>['Hello', '!', 'How', 'are', 'you', '?']</td>\n",
       "      <td>[This, is, an, example, sentence, in, English, .]</td>\n",
       "      <td>['This', 'is', 'an', 'example', 'sentence', 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Łatwość korzystania z tego narzędzia jest nies...</td>\n",
       "      <td>3</td>\n",
       "      <td>['Hello', '!', 'How', 'are', 'you', '?']</td>\n",
       "      <td>[Łatwość, korzystania, z, tego, narzędzia, jes...</td>\n",
       "      <td>['Łatwość', 'korzystania', 'z', 'tego', 'narzę...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The ease of use of this tool is amazing.</td>\n",
       "      <td>4</td>\n",
       "      <td>['Hello', '!', 'How', 'are', 'you', '?']</td>\n",
       "      <td>[The, ease, of, use, of, this, tool, is, amazi...</td>\n",
       "      <td>['The', 'ease', 'of', 'use', 'of', 'this', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cześć! Jak się masz?</td>\n",
       "      <td>5</td>\n",
       "      <td>['Hello', '!', 'How', 'are', 'you', '?']</td>\n",
       "      <td>[Cześć, !, Jak, się, masz, ?]</td>\n",
       "      <td>['Cześć', '!', 'Jak', 'się', 'masz', '?']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello! How are you?</td>\n",
       "      <td>6</td>\n",
       "      <td>['Hello', '!', 'How', 'are', 'you', '?']</td>\n",
       "      <td>[Hello, !, How, are, you, ?]</td>\n",
       "      <td>['Hello', '!', 'How', 'are', 'you', '?']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_col  target  \\\n",
       "0              To jest przykładowe zdanie po polsku.       1   \n",
       "1            This is an example sentence in English.       2   \n",
       "2  Łatwość korzystania z tego narzędzia jest nies...       3   \n",
       "3           The ease of use of this tool is amazing.       4   \n",
       "4                               Cześć! Jak się masz?       5   \n",
       "5                                Hello! How are you?       6   \n",
       "\n",
       "                                      final  \\\n",
       "0  ['Hello', '!', 'How', 'are', 'you', '?']   \n",
       "1  ['Hello', '!', 'How', 'are', 'you', '?']   \n",
       "2  ['Hello', '!', 'How', 'are', 'you', '?']   \n",
       "3  ['Hello', '!', 'How', 'are', 'you', '?']   \n",
       "4  ['Hello', '!', 'How', 'are', 'you', '?']   \n",
       "5  ['Hello', '!', 'How', 'are', 'you', '?']   \n",
       "\n",
       "                                               token  \\\n",
       "0     [To, jest, przykładowe, zdanie, po, polsku, .]   \n",
       "1  [This, is, an, example, sentence, in, English, .]   \n",
       "2  [Łatwość, korzystania, z, tego, narzędzia, jes...   \n",
       "3  [The, ease, of, use, of, this, tool, is, amazi...   \n",
       "4                      [Cześć, !, Jak, się, masz, ?]   \n",
       "5                       [Hello, !, How, are, you, ?]   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['To', 'jest', 'przykładowe', 'zdanie', 'po', ...  \n",
       "1  ['This', 'is', 'an', 'example', 'sentence', 'i...  \n",
       "2  ['Łatwość', 'korzystania', 'z', 'tego', 'narzę...  \n",
       "3  ['The', 'ease', 'of', 'use', 'of', 'this', 'to...  \n",
       "4          ['Cześć', '!', 'Jak', 'się', 'masz', '?']  \n",
       "5           ['Hello', '!', 'How', 'are', 'you', '?']  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "defe0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(X_train_tokens)\n",
    "Train_X_Tfidf = Tfidf_vect.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69e4438f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee26d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 26, 'jest': 12, 'przykładowe': 20, 'zdanie': 30, 'po': 18, 'polsku': 19, 'this': 25, 'is': 10, 'an': 1, 'example': 6, 'sentence': 21, 'in': 9, 'english': 5, 'łatwość': 31, 'korzystania': 13, 'tego': 23, 'narzędzia': 15, 'niesamowita': 16, 'the': 24, 'ease': 4, 'of': 17, 'use': 28, 'tool': 27, 'amazing': 0, 'cześć': 3, 'jak': 11, 'się': 22, 'masz': 14, 'hello': 7, 'how': 8, 'are': 2, 'you': 29}\n"
     ]
    }
   ],
   "source": [
    "print(Tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19fce2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 30)\t0.41987080495717866\n",
      "  (0, 26)\t0.41987080495717866\n",
      "  (0, 20)\t0.41987080495717866\n",
      "  (0, 19)\t0.41987080495717866\n",
      "  (0, 18)\t0.41987080495717866\n",
      "  (0, 12)\t0.3443000664000145\n",
      "  (1, 25)\t0.32554486881123057\n",
      "  (1, 21)\t0.39699901178248725\n",
      "  (1, 10)\t0.32554486881123057\n",
      "  (1, 9)\t0.39699901178248725\n",
      "  (1, 6)\t0.39699901178248725\n",
      "  (1, 5)\t0.39699901178248725\n",
      "  (1, 1)\t0.39699901178248725\n",
      "  (2, 31)\t0.41987080495717866\n",
      "  (2, 23)\t0.41987080495717866\n",
      "  (2, 16)\t0.41987080495717866\n",
      "  (2, 15)\t0.41987080495717866\n",
      "  (2, 13)\t0.41987080495717866\n",
      "  (2, 12)\t0.3443000664000145\n",
      "  (3, 28)\t0.3109123445439382\n",
      "  (3, 27)\t0.3109123445439382\n",
      "  (3, 25)\t0.25495257018877393\n",
      "  (3, 24)\t0.3109123445439382\n",
      "  (3, 17)\t0.6218246890878764\n",
      "  (3, 10)\t0.25495257018877393\n",
      "  (3, 4)\t0.3109123445439382\n",
      "  (3, 0)\t0.3109123445439382\n",
      "  (4, 22)\t0.5\n",
      "  (4, 14)\t0.5\n",
      "  (4, 11)\t0.5\n",
      "  (4, 3)\t0.5\n",
      "  (5, 29)\t0.5\n",
      "  (5, 8)\t0.5\n",
      "  (5, 7)\t0.5\n",
      "  (5, 2)\t0.5\n"
     ]
    }
   ],
   "source": [
    "print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e0e22ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36857b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd67a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdf8517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline(df_train, df_test):\n",
    "    X_train = df_train['text_col']\n",
    "    y_train = df_test['target']\n",
    "    X_test = df_train['text_col']\n",
    "    y_test = df_test['target']\n",
    "    X_train_tokens= [str(word_tokenize(entry)) for entry in X_train]\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "    Tfidf_vect.fit(X_train_tokens)\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
    "    Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "    \n",
    "    Naive = naive_bayes.MultinomialNB()\n",
    "    Naive.fit(Train_X_Tfidf, y_train)\n",
    "    predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "    print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
    "    return predictions_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec849083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad9c45bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4a3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
